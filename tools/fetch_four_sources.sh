#!/bin/bash

# ç”¨æ³•: ./fetch_four_sources.sh <slug> <English Name> <Scientific Name> [Wikipedia_Page_Name] [--sources <source1,source2,...>]
# 
# ä¼˜åŒ–è¯´æ˜ï¼š
# - å®¹é”™æ¨¡å¼ï¼šå•ä¸ªæºå¤±è´¥ä¸å½±å“å…¶ä»–æº
# - æ–‡ä»¶æ£€æµ‹ï¼šè·³è¿‡å·²ä¸‹è½½çš„æ–‡ä»¶
# - ä¼˜åŒ–æ€§èƒ½ï¼šç§»é™¤é‡å¤ API è°ƒç”¨
# - æ”¯æŒé€‰æ‹©ä¸‹è½½æŒ‡å®šæ¥æºï¼š--sources macaulay,inaturalist,wikimedia,avibase
#   é»˜è®¤ä¸‹è½½æ‰€æœ‰4ä¸ªæ¥æº

# æ³¨é‡Šæ‰ä¸¥æ ¼æ¨¡å¼ï¼Œæ”¹ä¸ºå®¹é”™æ¨¡å¼
# set -e
# set -o pipefail

# è§£æå‚æ•°
SLUG=""
EN_NAME=""
SCI_NAME=""
WIKI_PAGE_NAME=""
SOURCES=""  # è¦ä¸‹è½½çš„æ¥æºï¼Œé€—å·åˆ†éš”ï¼Œå¦‚ "macaulay,inaturalist"

# è§£æå‚æ•°ï¼šå…ˆæå– --sourcesï¼Œå†å¤„ç†ä½ç½®å‚æ•°
ARGS=()
while [[ $# -gt 0 ]]; do
  case $1 in
    --sources)
      SOURCES="$2"
      shift 2
      ;;
    *)
      ARGS+=("$1")
      shift
      ;;
  esac
done

# ä»ä½ç½®å‚æ•°ä¸­æå–
if [ ${#ARGS[@]} -ge 1 ]; then
  SLUG="${ARGS[0]}"
fi
if [ ${#ARGS[@]} -ge 2 ]; then
  EN_NAME="${ARGS[1]}"
fi
if [ ${#ARGS[@]} -ge 3 ]; then
  SCI_NAME="${ARGS[2]}"
fi
if [ ${#ARGS[@]} -ge 4 ]; then
  WIKI_PAGE_NAME="${ARGS[3]}"
fi

if [ -z "$SLUG" ] || [ -z "$EN_NAME" ] || [ -z "$SCI_NAME" ]; then
  echo "ç”¨æ³•: $0 <slug> <English Name> <Scientific Name> [Wikipedia_Page_Name] [--sources <source1,source2,...>]"
  echo "ç¤ºä¾‹: $0 bluetail 'Red-flanked Bluetail' 'Tarsiger cyanurus' Red-flanked_Bluetail"
  echo "      $0 bluetail 'Red-flanked Bluetail' 'Tarsiger cyanurus' Red-flanked_Bluetail --sources macaulay"
  echo "      $0 bluetail 'Red-flanked Bluetail' 'Tarsiger cyanurus' --sources macaulay,inaturalist"
  echo ""
  echo "å¯ç”¨æ¥æº: macaulay, inaturalist, wikimedia, avibase"
  echo "é»˜è®¤: ä¸‹è½½æ‰€æœ‰4ä¸ªæ¥æº"
  exit 1
fi

# å¦‚æœæ²¡æœ‰æŒ‡å®šæ¥æºï¼Œé»˜è®¤ä¸‹è½½æ‰€æœ‰
if [ -z "$SOURCES" ]; then
  SOURCES="macaulay,inaturalist,wikimedia,avibase"
fi

# æ£€æŸ¥æ˜¯å¦åº”è¯¥ä¸‹è½½æŸä¸ªæ¥æº
should_download() {
  local source="$1"
  echo "$SOURCES" | grep -q "$source"
}

ENC_EN_NAME=$(python3 -c "import urllib.parse,sys;print(urllib.parse.quote(sys.argv[1]))" "$EN_NAME" 2>/dev/null || echo "$EN_NAME")
WIKI_PAGE_NAME=${WIKI_PAGE_NAME:-$(echo "$EN_NAME" | tr ' ' '_' )}

BASE_DIR="images/$SLUG"
mkdir -p "$BASE_DIR/macaulay" "$BASE_DIR/inaturalist" "$BASE_DIR/wikimedia" "$BASE_DIR/avibase"

# åˆå§‹åŒ–å…ƒæ•°æ®æ–‡ä»¶
METADATA_FILE="$BASE_DIR/download_metadata.json"
if [ ! -f "$METADATA_FILE" ]; then
  echo '{"macaulay":[],"inaturalist":[],"wikimedia":[],"avibase":[]}' > "$METADATA_FILE"
fi

echo "=========================================="
echo "å¼€å§‹ä¸‹è½½: $EN_NAME"
echo "å­¦å: $SCI_NAME"
echo "Slug: $SLUG"
echo "=========================================="
echo ""

# 1) ç›´æ¥è°ƒ eBird taxonomy è·å– Species Codeï¼ˆä¼˜åŒ–ï¼šç§»é™¤é‡å¤è°ƒç”¨ + æ·»åŠ ç¼“å­˜ï¼‰
EBIRD_CODE=""
if [ -n "$EBIRD_TOKEN" ]; then
  # ä½¿ç”¨ curl è€Œé Python urllibï¼ˆé¿å… SSL è¯ä¹¦é—®é¢˜ï¼‰
  ENC_SCI_NAME=$(python3 -c "import urllib.parse,sys;print(urllib.parse.quote(sys.argv[1]))" "$SCI_NAME" 2>/dev/null || echo "$SCI_NAME")
  EBIRD_RESP=$(curl -s -H "X-eBirdApiToken: $EBIRD_TOKEN" \
    "https://api.ebird.org/v2/ref/taxonomy/ebird?fmt=json&locale=en&species=$ENC_SCI_NAME")
  
  if [ -n "$EBIRD_RESP" ]; then
    EBIRD_CODE=$(echo "$EBIRD_RESP" | python3 -c "import sys,json; d=json.load(sys.stdin); print(d[0]['speciesCode'] if d else '')" 2>/dev/null || echo "")
  fi
  
  # 1.2) å¦‚æœå­¦åæœªæ‰¾åˆ°ï¼Œç”¨è‹±æ–‡åä»å®Œæ•´ taxonomy ä¸­æŸ¥æ‰¾ï¼ˆåº”å¯¹å­¦ååˆ†ç±»å˜æ›´ï¼‰
  if [ -z "$EBIRD_CODE" ]; then
    echo "[æ—¥å¿—] å­¦åæœªæ‰¾åˆ°ï¼Œå°è¯•ç”¨è‹±æ–‡åä» eBird taxonomy ä¸­æŸ¥æ‰¾â€¦"
    
    # ä¼˜åŒ–ï¼šä½¿ç”¨ç¼“å­˜ï¼ˆæœˆåº¦æ›´æ–°ï¼‰
    CACHE_DIR="$HOME/.cache/bird_memory_cards"
    mkdir -p "$CACHE_DIR"
    CACHE_FILE="$CACHE_DIR/ebird_taxonomy_$(date +%Y%m).json"
    
    if [ -f "$CACHE_FILE" ]; then
      echo "[æ—¥å¿—] ä½¿ç”¨ç¼“å­˜çš„ eBird taxonomyï¼ˆ$(date +%Y-%m)ï¼‰"
      EBIRD_FULL=$(cat "$CACHE_FILE")
    else
      echo "[æ—¥å¿—] ä¸‹è½½å®Œæ•´ eBird taxonomyï¼ˆé¦–æ¬¡æˆ–æœˆåº¦æ›´æ–°ï¼‰..."
      EBIRD_FULL=$(curl -s -H "X-eBirdApiToken: $EBIRD_TOKEN" \
        "https://api.ebird.org/v2/ref/taxonomy/ebird?fmt=json&locale=en")
      # ä¿å­˜åˆ°ç¼“å­˜
      echo "$EBIRD_FULL" > "$CACHE_FILE"
      echo "[æ—¥å¿—] å·²ç¼“å­˜åˆ°: $CACHE_FILE"
    fi
    
    if [ -n "$EBIRD_FULL" ]; then
      EBIRD_CODE=$(echo "$EBIRD_FULL" | EN_NAME="$EN_NAME" SCI_NAME="$SCI_NAME" python3 -c 'import sys,json,os
d=json.load(sys.stdin)
en=os.environ.get("EN_NAME","").strip().lower()
sci=os.environ.get("SCI_NAME","").strip().lower()
# å…ˆç”¨å­¦åç²¾ç¡®åŒ¹é…ï¼ˆä¸å— locale å½±å“ï¼‰
code=""
for item in d:
    if item.get("sciName"," ").strip().lower()==sci:
        code=item.get("speciesCode","")
        break
if not code:
    for item in d:
        if item.get("comName"," ").strip().lower()==en:
            code=item.get("speciesCode","")
            break
print(code)
' 2>/dev/null || echo "")
      
      if [ -n "$EBIRD_CODE" ]; then
        echo "[æ—¥å¿—] é€šè¿‡è‹±æ–‡åæ‰¾åˆ° speciesCode: $EBIRD_CODE (eBirdå­¦å: $(echo "$EBIRD_FULL" | EBIRD_CODE="$EBIRD_CODE" python3 -c 'import sys,json,os; d=json.load(sys.stdin); code=os.environ.get("EBIRD_CODE",""); print(next((item.get("sciName","") for item in d if item.get("speciesCode","")==code), ""))' 2>/dev/null || echo ""))"
      fi
    fi
  fi
fi

if [ -n "$EBIRD_CODE" ]; then
  echo "[æ—¥å¿—] eBird taxonomy speciesCode: $EBIRD_CODE" 
  echo "[æ—¥å¿—] Macaulayé¡µé¢(ç”¨speciesCodeå……å½“taxonCode): https://search.macaulaylibrary.org/catalog?taxonCode=$EBIRD_CODE&sort=rating_rank_desc"
else
  echo "[æ—¥å¿—] eBird taxonomy speciesCode: æ— " 
fi

# ä¸‹è½½ Macaulay ç…§ç‰‡çš„å‡½æ•°
download_macaulay() {
if should_download "macaulay"; then
echo "ğŸ“¥ [1/4] Macaulay Library"

# ç›´æ¥ä½¿ç”¨ eBird code ä½œä¸º Macaulay taxonCodeï¼ˆæ— éœ€ API æœç´¢å­¦å/è‹±æ–‡åï¼‰
ML_CODE=""
if [ -n "$EBIRD_CODE" ]; then
  ML_CODE="$EBIRD_CODE"
  echo "  [æ—¥å¿—] ä½¿ç”¨ eBird speciesCode: $ML_CODE"
fi

# å¦‚æœæœªå–åˆ° eBird codeï¼Œå°è¯•ä» Macaulay suggest API è·å–
if [ -z "$ML_CODE" ]; then
  echo "  [æ—¥å¿—] eBird æœªè¿”å› codeï¼Œå°è¯•ä» Macaulay suggest API è·å–â€¦"
  
  # å…ˆå°è¯•å­¦å
  SUGGEST_RESP=$(curl -s -H "Accept: application/json" -H "User-Agent: Mozilla/5.0" \
    "https://search.macaulaylibrary.org/api/v1/suggest?q=$(python3 -c "import urllib.parse,sys;print(urllib.parse.quote(sys.argv[1]))" "$SCI_NAME" 2>/dev/null || echo "$SCI_NAME")" || echo "")
  
  if [ -n "$SUGGEST_RESP" ]; then
    ML_CODE=$(echo "$SUGGEST_RESP" | python3 -c 'import sys,json; d=json.load(sys.stdin); print(d[0].get("code","") if isinstance(d,list) and d else "")' 2>/dev/null || echo "")
  fi
  
  # å¦‚æœå­¦åæ²¡æ‰¾åˆ°ï¼Œå°è¯•è‹±æ–‡å
  if [ -z "$ML_CODE" ]; then
    echo "  [æ—¥å¿—] å­¦åæœªå‘½ä¸­ï¼Œæ”¹ç”¨è‹±æ–‡åâ€¦"
    SUGGEST_RESP=$(curl -s -H "Accept: application/json" -H "User-Agent: Mozilla/5.0" \
      "https://search.macaulaylibrary.org/api/v1/suggest?q=$(python3 -c "import urllib.parse,sys;print(urllib.parse.quote(sys.argv[1]))" "$EN_NAME" 2>/dev/null || echo "$EN_NAME")" || echo "")
    
    if [ -n "$SUGGEST_RESP" ]; then
      ML_CODE=$(echo "$SUGGEST_RESP" | python3 -c 'import sys,json; d=json.load(sys.stdin); print(d[0].get("code","") if isinstance(d,list) and d else "")' 2>/dev/null || echo "")
    fi
  fi
fi

if [ -z "$ML_CODE" ]; then
  echo "  âŒ æœªé€šè¿‡ eBird/Macaulay API è·å–åˆ° speciesCodeï¼ˆå­¦åï¼š$SCI_NAMEï¼Œè‹±æ–‡åï¼š$EN_NAMEï¼‰"
  echo "  æç¤ºï¼šè¯¥ç‰©ç§å¯èƒ½ä¸åœ¨ eBird/Macaulay æ•°æ®åº“ä¸­ï¼Œè·³è¿‡ Macaulay ä¸‹è½½"
  ASSETS=""
else
  echo "  [æ—¥å¿—] ä½¿ç”¨ taxonCode=$ML_CODE æŸ¥è¯¢ç…§ç‰‡â€¦"
  RESPONSE=$(curl -s -H "Accept: application/json" -H "User-Agent: Mozilla/5.0" \
    "https://search.macaulaylibrary.org/api/v1/search?taxonCode=${ML_CODE}&mediaType=p&sort=rating_rank_desc&count=20")
  ASSETS=$(echo "$RESPONSE" | python3 -c 'import sys,json
d=json.load(sys.stdin)
for a in (d.get("results",{}) or {}).get("content",[]) or []:
    aid=a.get("assetId") or a.get("catalogId")
    if aid: print(aid)
')
fi
COUNT=0
MACAULAY_META="[]"
for ASSET_ID in $ASSETS; do
  [ $COUNT -ge 3 ] && break
  OUT="$BASE_DIR/macaulay/${SLUG}_$ASSET_ID.jpg"
  
  # ä¼˜åŒ–ï¼šæ£€æµ‹æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ä¸”æœ‰æ•ˆ
  if [ -f "$OUT" ] && file "$OUT" 2>/dev/null | grep -q "JPEG\|PNG\|image"; then
    echo "  â­ï¸  å·²å­˜åœ¨: $OUT"
    COUNT=$((COUNT+1))
    # ä¿å­˜å…ƒæ•°æ®
    MACAULAY_META=$(echo "$MACAULAY_META" | python3 -c "import sys,json; d=json.load(sys.stdin); d.append({'filename':'${SLUG}_${ASSET_ID}.jpg','asset_id':'$ASSET_ID','asset_url':'https://macaulaylibrary.org/asset/$ASSET_ID'}); print(json.dumps(d))")
    continue
  fi
  
  # ä¸‹è½½æ–‡ä»¶ï¼ˆå®¹é”™ï¼šå¤±è´¥ä¸é€€å‡ºï¼‰
  curl -s -o "$OUT" "https://cdn.download.ams.birds.cornell.edu/api/v2/asset/${ASSET_ID}/1200" || {
    echo "  âš ï¸  ä¸‹è½½å¤±è´¥: $ASSET_ID"
    continue
  }
  
  if file "$OUT" 2>/dev/null | grep -q "JPEG\|PNG\|image"; then
    COUNT=$((COUNT+1))
    echo "  âœ… Macaulay: $OUT"
    # ä¿å­˜å…ƒæ•°æ®
    MACAULAY_META=$(echo "$MACAULAY_META" | python3 -c "import sys,json; d=json.load(sys.stdin); d.append({'filename':'${SLUG}_${ASSET_ID}.jpg','asset_id':'$ASSET_ID','asset_url':'https://macaulaylibrary.org/asset/$ASSET_ID'}); print(json.dumps(d))")
  else
    rm -f "$OUT"
  fi
done

# ä¿å­˜ Macaulay å…ƒæ•°æ®
python3 -c "import sys,json; data=json.load(open('$METADATA_FILE')); data['macaulay']=json.loads('$MACAULAY_META'); json.dump(data, open('$METADATA_FILE','w'), indent=2)"

echo "  [æ—¥å¿—] Macaulay æœ€ç»ˆä¸‹è½½æ•°é‡: $COUNT"

# HTML å›é€€ï¼šè‹¥ API æœªè·å–åˆ°ä»»ä½• assetï¼Œåˆ™è§£ææœç´¢é¡µé¢ HTML æå– assetId
: # æŒ‰æ–°è§„åˆ™ï¼šæœªè·å–åˆ° code æ—¶ä¸å†ä½¿ç”¨ HTML å›é€€ï¼Œç›´æ¥ç»“æŸ Macaulay æµç¨‹
else
  echo "â­ï¸  è·³è¿‡ Macaulay Libraryï¼ˆæœªåœ¨ --sources ä¸­æŒ‡å®šï¼‰"
fi
}

# ä¸‹è½½ iNaturalist ç…§ç‰‡çš„å‡½æ•°
download_inaturalist() {
if should_download "inaturalist"; then
echo ""
echo "ğŸ“¥ [2/4] iNaturalist"
INAT_URL="https://api.inaturalist.org/v1/observations?taxon_name=$(echo "$SCI_NAME" | sed 's/ /%20/g')&quality_grade=research&photos=true&per_page=10&order_by=votes"
echo "  [æ—¥å¿—] iNat API: $INAT_URL"

# è·å–å®Œæ•´çš„è§‚å¯Ÿæ•°æ®ï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰
INAT_DATA=$(curl -s "$INAT_URL" 2>/dev/null) || {
  echo "  âš ï¸  iNaturalist API è°ƒç”¨å¤±è´¥ï¼Œè·³è¿‡"
  INAT_DATA=""
}

ICOUNT=0
INAT_META="[]"
if [ -n "$INAT_DATA" ]; then
  # ä½¿ç”¨Pythonå¤„ç†JSONå¹¶ä¸‹è½½
  echo "$INAT_DATA" | python3 -c "
import sys, json, subprocess
try:
    data = json.load(sys.stdin)
    results = data.get('results', [])
    count = 0
    metadata = []
    
    for obs in results[:3]:
        photos = obs.get('photos', [])
        if not photos:
            continue
        
        photo = photos[0]
        user = obs.get('user', {})
        obs_id = obs.get('id')
        photo_id = photo.get('id')
        url = photo.get('url', '').replace('square', 'large')
        license_code = photo.get('license_code', '')
        
        filename = '${SLUG}_' + str(count+1) + '.jpg'
        out_path = '$BASE_DIR/inaturalist/' + filename
        
        # ä¸‹è½½å›¾ç‰‡
        result = subprocess.run(['curl', '-s', '-o', out_path, url], capture_output=True)
        
        if result.returncode == 0:
            # éªŒè¯æ–‡ä»¶
            verify = subprocess.run(['file', out_path], capture_output=True, text=True)
            if 'JPEG' in verify.stdout or 'PNG' in verify.stdout:
                count += 1
                print(f'  âœ… iNat: {filename}')
                
                # ç”Ÿæˆå¼•ç”¨æ ¼å¼
                if license_code:
                    credit = f'Â© {user.get(\"login\", \"Unknown\")} (via iNaturalist), some rights reserved ({license_code.upper()})'
                else:
                    credit = f'Â© {user.get(\"login\", \"Unknown\")} (via iNaturalist), All Rights Reserved'
                
                # ä¿å­˜å…ƒæ•°æ®
                metadata.append({
                    'filename': filename,
                    'observation_id': obs_id,
                    'photo_id': photo_id,
                    'observation_url': f'https://www.inaturalist.org/observations/{obs_id}',
                    'photographer': user.get('login'),
                    'license': license_code or 'all-rights-reserved',
                    'credit_format': credit
                })
                
                if count >= 3:
                    break
    
    # è¾“å‡ºå…ƒæ•°æ®JSON
    print('__METADATA_START__')
    print(json.dumps(metadata))
    print('__METADATA_END__')
    
except Exception as e:
    print(f'  âš ï¸  å¤„ç†å¤±è´¥: {e}', file=sys.stderr)
" | tee /tmp/inat_output.txt
  
  # æå–å…ƒæ•°æ®
  INAT_META=$(cat /tmp/inat_output.txt | sed -n '/__METADATA_START__/,/__METADATA_END__/p' | grep -v '__METADATA_' || echo "[]")
  ICOUNT=$(echo "$INAT_META" | python3 -c "import sys,json; print(len(json.load(sys.stdin)))" 2>/dev/null || echo "0")
  
  # ä¿å­˜å…ƒæ•°æ®
  if [ -n "$INAT_META" ] && [ "$INAT_META" != "[]" ]; then
    python3 -c "import sys,json; data=json.load(open('$METADATA_FILE')); data['inaturalist']=$INAT_META; json.dump(data, open('$METADATA_FILE','w'), indent=2)" 2>/dev/null || true
  fi
fi

echo "  [æ—¥å¿—] iNat ä¸‹è½½æ•°é‡: $ICOUNT"
else
  echo "â­ï¸  è·³è¿‡ iNaturalistï¼ˆæœªåœ¨ --sources ä¸­æŒ‡å®šï¼‰"
fi
}

# ä¸‹è½½ Wikimedia ç…§ç‰‡çš„å‡½æ•°
download_wikimedia() {
if should_download "wikimedia"; then
echo ""
echo "ğŸ“¥ [3/4] Wikimedia (from Wikipedia: $WIKI_PAGE_NAME)"
WIKI_HTML=$(curl -s "https://en.wikipedia.org/wiki/$WIKI_PAGE_NAME" 2>/dev/null) || {
  echo "  âš ï¸  Wikipedia é¡µé¢è·å–å¤±è´¥ï¼Œè·³è¿‡"
  WIKI_HTML=""
}

WCOUNT=0
WIKI_META="[]"
if [ -n "$WIKI_HTML" ]; then
  # æå–å›¾ç‰‡æ–‡ä»¶åå¹¶è·å–å…ƒæ•°æ®
  echo "$WIKI_HTML" | grep -o 'upload\.wikimedia\.org/wikipedia/commons/thumb/[^/]*/[^/]*/\([^/]*\.jpg\)/[0-9]*px-[^\"]*\.jpg' | head -5 | while read U; do
    [ $WCOUNT -ge 1 ] && break
    
    # æå–åŸå§‹æ–‡ä»¶å
    ORIG_FILENAME=$(echo "$U" | sed -n 's|.*/\([^/]*\.jpg\)/.*|\1|p')
    
    # è¿‡æ»¤æ ‡æœ¬/æ’å›¾
    if echo "$ORIG_FILENAME" | grep -qi "MHNT\|Dresser\|map\|range\|illustration"; then
      continue
    fi
    
    OUT="$BASE_DIR/wikimedia/${SLUG}_$((WCOUNT+1)).jpg"
    
    # ä¸‹è½½æ–‡ä»¶
    curl -s -o "$OUT" "https://$U" || {
      echo "  âš ï¸  ä¸‹è½½å¤±è´¥: $U"
      continue
    }
    
    if file "$OUT" 2>/dev/null | grep -q "JPEG\|PNG"; then
      WCOUNT=$((WCOUNT+1))
      echo "  âœ… Wikimedia: $OUT (åŸæ–‡ä»¶: $ORIG_FILENAME)"
      
      # è·å– Wikimedia Commons å…ƒæ•°æ®
      WIKI_API_URL="https://commons.wikimedia.org/w/api.php?action=query&format=json&prop=imageinfo&titles=File:${ORIG_FILENAME}&iiprop=extmetadata"
      WIKI_METADATA=$(curl -s "$WIKI_API_URL" | python3 -c "
import sys, json, re
try:
    data = json.load(sys.stdin)
    pages = data.get('query', {}).get('pages', {})
    for page in pages.values():
        imageinfo = page.get('imageinfo', [])
        if imageinfo:
            metadata = imageinfo[0].get('extmetadata', {})
            artist = metadata.get('Artist', {}).get('value', 'Unknown')
            license_short = metadata.get('LicenseShortName', {}).get('value', 'Unknown')
            license_url = metadata.get('LicenseUrl', {}).get('value', '')
            attribution = metadata.get('Attribution', {}).get('value', '')
            
            # æ¸…ç†HTMLæ ‡ç­¾
            artist_clean = re.sub(r'<[^>]+>', '', artist)
            attribution_clean = re.sub(r'<[^>]+>', '', attribution)
            
            if not attribution_clean:
                attribution_clean = f'{artist_clean}, {license_short}, via Wikimedia Commons'
            
            result = {
                'filename': '${SLUG}_$((WCOUNT)).jpg',
                'original_filename': '${ORIG_FILENAME}',
                'commons_url': 'https://commons.wikimedia.org/wiki/File:${ORIG_FILENAME}',
                'photographer': artist_clean,
                'license': license_short,
                'license_url': license_url,
                'credit_format': attribution_clean
            }
            print(json.dumps(result))
            break
except Exception as e:
    print('{}')
" 2>/dev/null)
      
      # æ·»åŠ åˆ°å…ƒæ•°æ®æ•°ç»„
      if [ -n "$WIKI_METADATA" ] && [ "$WIKI_METADATA" != "{}" ]; then
        WIKI_META=$(echo "$WIKI_META" | python3 -c "import sys,json; d=json.load(sys.stdin); d.append($WIKI_METADATA); print(json.dumps(d))")
      fi
    else
      rm -f "$OUT"
    fi
  done
  
  # ä¿å­˜ Wikimedia å…ƒæ•°æ®
  if [ -n "$WIKI_META" ] && [ "$WIKI_META" != "[]" ]; then
    python3 -c "import sys,json; data=json.load(open('$METADATA_FILE')); data['wikimedia']=json.loads('$WIKI_META'); json.dump(data, open('$METADATA_FILE','w'), indent=2)" 2>/dev/null || true
  fi
fi

echo "  [æ—¥å¿—] Wikimedia ä¸‹è½½æ•°é‡: $WCOUNT"
else
  echo "â­ï¸  è·³è¿‡ Wikimediaï¼ˆæœªåœ¨ --sources ä¸­æŒ‡å®šï¼‰"
fi
}

# ä¸‹è½½ Avibase ç…§ç‰‡çš„å‡½æ•°
download_avibase() {
if should_download "avibase"; then
echo ""
echo "ğŸ“¥ [4/4] Avibase (Flickr via CN æ¸…å• + sec=flickr)"
python3 tools/download_from_avibase.py "$EN_NAME" "$SCI_NAME" "$BASE_DIR/avibase" 3 || true
else
  echo "â­ï¸  è·³è¿‡ Avibaseï¼ˆæœªåœ¨ --sources ä¸­æŒ‡å®šï¼‰"
fi
}

# ä¸»æµç¨‹ï¼šè°ƒç”¨å„ä¸ªä¸‹è½½å‡½æ•°
download_macaulay
download_inaturalist
download_wikimedia
download_avibase

echo ""
echo "å®Œæˆ: $SLUG"


