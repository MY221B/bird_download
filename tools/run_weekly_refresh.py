#!/usr/bin/env python3
"""
æ‰¹é‡åˆ·æ–°æ‰€æœ‰åœ°ç‚¹çš„é¸Ÿå•å¹¶æ›´æ–°å›¾ç‰‡/JSON/å±•ç¤ºæ•°æ®
"""

import argparse
import csv
import json
import os
import re
import shutil
import subprocess
import sys
import unicodedata
from collections import OrderedDict
from datetime import datetime, date, timedelta
from pathlib import Path

PROJECT_ROOT = Path(__file__).parent.parent.resolve()
CONFIG_PATH = PROJECT_ROOT / "config" / "birdreport_locations.json"
LOCATION_BIRDS_DIR = PROJECT_ROOT / "feather-flash-quiz" / "location_birds"
TMP_BASE = PROJECT_ROOT / "tmp" / "weekly_refresh"
MIN_SPECIES_DEFAULT = 10
MAX_RETRIES = 2

sys.path.insert(0, str(PROJECT_ROOT / "tools"))
from location_utils import get_location_birds_path
from process_new_birds import (  # type: ignore
    load_all_birds_csv,
    merge_with_all_birds_csv,
    check_missing_birds,
    download_birds,
    check_missing_cloudinary,
    upload_to_cloudinary,
    update_bird_info,
    update_all_birds_csv,
    generate_html,
    reorder_new_birds,
)
from fetch_from_birdreport import fetch_birds_for_payload  # type: ignore
from auto_sounds_refresh import (  # type: ignore
    download_and_upload_sounds,
    print_sounds_summary,
)
BIRD_INFO_CACHE = load_all_birds_csv()


def parse_args():
    parser = argparse.ArgumentParser(
        description="æŒ‰åœ°ç‚¹æ‰¹é‡åˆ·æ–°é¸Ÿç±»å›¾ç‰‡å¹¶å¤åˆ¶ Cloudinary JSON"
    )
    parser.add_argument(
        "--locations",
        nargs="+",
        help="ä»…å¤„ç†æŒ‡å®šåœ°ç‚¹ï¼ˆå¯ç”¨ id æˆ– nameï¼‰",
    )
    parser.add_argument(
        "--days",
        type=int,
        default=7,
        help="é»˜è®¤æ‹‰å–çš„å¤©æ•°ï¼ˆæœªæŒ‡å®š --start/--end æ—¶ç”Ÿæ•ˆï¼Œé»˜è®¤ 7ï¼‰",
    )
    parser.add_argument(
        "--start",
        help="è¦†ç›–æ‰€æœ‰åœ°ç‚¹çš„å¼€å§‹æ—¥æœŸ YYYY-MM-DD",
    )
    parser.add_argument(
        "--end",
        help="è¦†ç›–æ‰€æœ‰åœ°ç‚¹çš„ç»“æŸæ—¥æœŸ YYYY-MM-DD",
    )
    parser.add_argument(
        "--min-species",
        type=int,
        default=MIN_SPECIES_DEFAULT,
        help="è‹¥å»é‡é¸Ÿç§å°‘äºè¯¥å€¼åˆ™è·³è¿‡æ›´æ–°ï¼ˆé»˜è®¤ 10ï¼‰",
    )
    return parser.parse_args()


def load_locations():
    if not CONFIG_PATH.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶: {CONFIG_PATH}")
    data = json.loads(CONFIG_PATH.read_text(encoding="utf-8"))
    locations = data.get("locations", data)
    if not isinstance(locations, list):
        raise ValueError("é…ç½®æ ¼å¼é”™è¯¯ï¼Œéœ€è¦åˆ—è¡¨æˆ–åŒ…å« locations å­—æ®µçš„å¯¹è±¡")
    return locations


def maybe_filter_locations(locations, targets):
    if not targets:
        return locations
    normalized = {t.lower() for t in targets}
    filtered = []
    for entry in locations:
        if (
            entry.get("id", "").lower() in normalized
            or entry.get("name", "").lower() in normalized
        ):
            filtered.append(entry)
    if not filtered:
        raise ValueError("æ²¡æœ‰åŒ¹é…çš„åœ°ç‚¹ã€‚è¯·æ£€æŸ¥ --locations å‚æ•°ã€‚")
    return filtered


def parse_date_value(value, fallback=None):
    if not value:
        return fallback
    return datetime.strptime(value, "%Y-%m-%d").date()


def resolve_date_range(entry, args):
    end_date = parse_date_value(args.end, date.today())
    start_date = parse_date_value(args.start, None)
    days = args.days if args.days is not None else entry.get("default_days", 7)
    if start_date is None:
        start_date = end_date - timedelta(days=max(1, days) - 1)
    if start_date > end_date:
        raise ValueError(f"å¼€å§‹æ—¥æœŸ {start_date} æ™šäºç»“æŸæ—¥æœŸ {end_date}")
    return start_date, end_date


def build_payload(entry, start, end, alias, query_level="point", district_override=None):
    """
    æ„å»º API æŸ¥è¯¢çš„ payload
    
    query_level å¯é€‰å€¼:
    - "point" (é»˜è®¤): åœ°ç‚¹çº§åˆ«æŸ¥è¯¢ï¼Œä½¿ç”¨ pointname
    - "district": åŒºå¿çº§åˆ«æŸ¥è¯¢ï¼Œæ¸…ç©º pointname
    - "city": åŸå¸‚çº§åˆ«æŸ¥è¯¢ï¼Œæ¸…ç©º district å’Œ pointname
    - "province": çœçº§åˆ«æŸ¥è¯¢ï¼Œæ¸…ç©º cityã€district å’Œ pointname
    
    district_override: è¦†ç›– entry ä¸­çš„ district å­—æ®µï¼ˆç”¨äºå¤šåŒºå¿æŸ¥è¯¢ï¼‰
    """
    payload = {
        "taxonid": entry.get("taxonid", ""),
        "startTime": start.strftime("%Y-%m-%d"),
        "endTime": end.strftime("%Y-%m-%d"),
        "province": entry.get("province", ""),
        "city": entry.get("city", ""),
        "district": district_override if district_override is not None else entry.get("district", ""),
        "pointname": alias if alias else "",
        "username": entry.get("username", ""),
        "serial_id": entry.get("serial_id", ""),
        "ctime": entry.get("ctime", ""),
        "version": entry.get("version", "CH4"),
        "state": entry.get("state", ""),
        "mode": entry.get("mode", "0"),
        "taxon_month": entry.get("taxon_month", ""),
        "outside_type": entry.get("outside_type", "0"),
        "limit": entry.get("limit", "1500"),
        "page": entry.get("page", "1"),
    }
    
    # æ ¹æ®æŸ¥è¯¢çº§åˆ«æ¸…ç©ºç›¸åº”å­—æ®µ
    if query_level == "province":
        payload["city"] = ""
        payload["district"] = ""
        payload["pointname"] = ""
    elif query_level == "city":
        payload["district"] = ""
        payload["pointname"] = ""
    elif query_level == "district":
        payload["pointname"] = ""
    
    return payload


def fetch_species_for_location(entry, start, end, output_file):
    """
    æ ¹æ®åœ°ç‚¹é…ç½®è·å–é¸Ÿç§æ•°æ®
    
    æ”¯æŒä¸åŒçš„æŸ¥è¯¢çº§åˆ«:
    - point: åœ°ç‚¹çº§åˆ«ï¼Œä½¿ç”¨ point_aliases åˆ—è¡¨æŸ¥è¯¢
    - district: åŒºå¿çº§åˆ«ï¼ŒæŸ¥è¯¢æ•´ä¸ªåŒºå¿ï¼ˆæ”¯æŒ districts æ•°ç»„æŸ¥è¯¢å¤šä¸ªåŒºå¿ï¼‰
    - city: åŸå¸‚çº§åˆ«ï¼ŒæŸ¥è¯¢æ•´ä¸ªåŸå¸‚
    - province: çœçº§åˆ«ï¼ŒæŸ¥è¯¢æ•´ä¸ªçœä»½
    """
    query_level = entry.get("query_level", "point")
    location_name = entry.get("name", "æœªçŸ¥åœ°ç‚¹")
    combined = OrderedDict()
    
    # æ ¹æ®æŸ¥è¯¢çº§åˆ«å†³å®šæŸ¥è¯¢æ–¹å¼
    if query_level == "district":
        # åŒºå¿çº§åˆ«æŸ¥è¯¢ï¼šæ”¯æŒå•ä¸ªæˆ–å¤šä¸ªåŒºå¿
        districts = entry.get("districts", [])
        
        if districts:
            # å¤šåŒºå¿æŸ¥è¯¢ï¼šéå†æ¯ä¸ªåŒºå¿
            print(f"ğŸ” {location_name} - å¤šåŒºå¿æŸ¥è¯¢: {len(districts)} ä¸ªåŒºå¿")
            for district in districts:
                if not district:
                    continue
                print(f"  ğŸ” {district}: è°ƒç”¨ API ...")
                payload = build_payload(entry, start, end, None, query_level="district", district_override=district)
                try:
                    records = fetch_birds_for_payload(payload)
                    print(f"  âœ… {district}: è¿”å› {len(records)} æ¡è®°å½•")
                    for record in records:
                        key = (record.chinese, record.scientific)
                        if key not in combined:
                            combined[key] = record
                except Exception as exc:
                    print(f"  âš ï¸  {district} æŸ¥è¯¢å¤±è´¥: {exc}")
                    continue
            
            if not combined:
                raise RuntimeError("æ‰€æœ‰åŒºå¿æŸ¥è¯¢éƒ½æœªè¿”å›ç»“æœ")
        else:
            # å•åŒºå¿æŸ¥è¯¢ï¼šä½¿ç”¨é…ç½®ä¸­çš„ district å­—æ®µ
            print(f"ğŸ” {location_name} - åŒºå¿çº§åˆ«æŸ¥è¯¢: è°ƒç”¨ API ...")
            payload = build_payload(entry, start, end, None, query_level="district")
            try:
                records = fetch_birds_for_payload(payload)
                print(f"âœ… åŒºå¿çº§åˆ«: è¿”å› {len(records)} æ¡è®°å½•")
                for record in records:
                    key = (record.chinese, record.scientific)
                    if key not in combined:
                        combined[key] = record
            except Exception as exc:
                print(f"âš ï¸  åŒºå¿çº§åˆ«æŸ¥è¯¢å¤±è´¥: {exc}")
                raise RuntimeError(f"åŒºå¿çº§åˆ«æŸ¥è¯¢å¤±è´¥: {exc}")
    
    elif query_level in ["province", "city"]:
        # çœçº§æˆ–åŸå¸‚çº§åˆ«æŸ¥è¯¢
        level_names = {
            "province": "çœçº§åˆ«",
            "city": "åŸå¸‚çº§åˆ«"
        }
        level_name = level_names.get(query_level, query_level)
        print(f"ğŸ” {location_name} - {level_name}æŸ¥è¯¢: è°ƒç”¨ API ...")
        
        payload = build_payload(entry, start, end, None, query_level=query_level)
        try:
            records = fetch_birds_for_payload(payload)
            print(f"âœ… {level_name}: è¿”å› {len(records)} æ¡è®°å½•")
            for record in records:
                key = (record.chinese, record.scientific)
                if key not in combined:
                    combined[key] = record
        except Exception as exc:
            print(f"âš ï¸  {level_name}æŸ¥è¯¢å¤±è´¥: {exc}")
            raise RuntimeError(f"{level_name}æŸ¥è¯¢å¤±è´¥: {exc}")
    
    else:
        # åœ°ç‚¹çº§åˆ«æŸ¥è¯¢ï¼ˆé»˜è®¤ï¼‰ï¼šä½¿ç”¨ point_aliases
        aliases = entry.get("point_aliases") or [entry.get("pointname") or entry.get("name")]
        for alias in aliases:
            if not alias:
                continue
            print(f"ğŸ” {location_name} - {alias}: è°ƒç”¨ API ...")
            payload = build_payload(entry, start, end, alias, query_level="point")
            try:
                records = fetch_birds_for_payload(payload)
            except Exception as exc:
                print(f"âš ï¸  {alias} æŠ“å–å¤±è´¥: {exc}")
                continue
            print(f"âœ… {alias}: è¿”å› {len(records)} æ¡è®°å½•")
            for record in records:
                key = (record.chinese, record.scientific)
                if key not in combined:
                    combined[key] = record
    
    if not combined:
        raise RuntimeError("æ‰€æœ‰æœç´¢è¯éƒ½æœªè¿”å›ç»“æœ")
    
    with open(output_file, "w", encoding="utf-8") as f:
        for record in combined.values():
            line = f"{record.chinese} {record.english or ''} {record.scientific or ''}".strip()
            f.write(f"{line}\n")
    return list(combined.values())


def remove_accents(text):
    return "".join(
        char
        for char in unicodedata.normalize("NFD", text)
        if unicodedata.category(char) != "Mn"
    )


def generate_slug(name):
    if not name:
        return ""
    name = remove_accents(name)
    name = name.lower()
    name = re.sub(r"[^\w\s-]", "", name)
    name = re.sub(r"[-\s]+", "_", name)
    return name.strip("_")


def write_csv_from_records(records, csv_file):
    lines = ['# slug,chinese_name,english_name,scientific_name,wikipedia_page']
    slug_map = {}
    for record in records:
        base_name = record.english or record.scientific or record.chinese
        slug = generate_slug(base_name)
        chinese = (record.chinese or "").replace('"', '""')
        english = (record.english or "").replace('"', '""')
        scientific = (record.scientific or "").replace('"', '""')
        wiki = ""
        if english:
            wiki = english.replace(" ", "_")
        lines.append(f'{slug},"{chinese}","{english}","{scientific}",{wiki}')
        slug_map[slug] = {
            "chinese_name": record.chinese or "",
            "english_name": record.english or "",
            "scientific_name": record.scientific or "",
        }
    csv_file.write_text("\n".join(lines) + "\n", encoding="utf-8")
    return slug_map


def format_slug(slug, local_info):
    info = (local_info or {}).get(slug) or BIRD_INFO_CACHE.get(slug)
    if not info:
        return slug
    chinese = info.get("chinese_name") or info.get("chinese")
    english = info.get("english_name") or info.get("english")
    label = english or slug
    if chinese:
        return f"{label}ï¼ˆ{chinese}ï¼‰"
    return label


def format_slug_list(slugs, local_info):
    if not slugs:
        return []
    return [format_slug(slug, local_info) for slug in slugs]


def read_slugs_from_csv(csv_file):
    slugs = []
    with open(csv_file, encoding="utf-8") as f:
        filtered = [
            line for line in f.readlines() if line.strip() and not line.startswith("#")
        ]
        reader = csv.reader(filtered)
        for row in reader:
            if not row:
                continue
            slug = row[0].strip().strip('"')
            if slug and slug.lower() != "slug":
                slugs.append(slug)
    return slugs


def copy_json_to_location(slugs, location_name, report_code):
    # ä½¿ç”¨æ–°çš„æ–‡ä»¶å¤¹ç»“æ„ï¼šåŸå¸‚/åœ°ç‚¹/æ—¥æœŸ
    dest_dir = get_location_birds_path(location_name, report_code)
    dest_dir.mkdir(parents=True, exist_ok=True)
    copied = 0
    missing = []
    for slug in slugs:
        src = PROJECT_ROOT / "cloudinary_uploads" / f"{slug}_cloudinary_urls.json"
        if src.exists():
            shutil.copy2(src, dest_dir / src.name)
            copied += 1
        else:
            missing.append(slug)
    return dest_dir, copied, missing


def ensure_tmp_dir():
    TMP_BASE.mkdir(parents=True, exist_ok=True)
    batch_dir = TMP_BASE / datetime.now().strftime("%Y%m%d_%H%M%S")
    batch_dir.mkdir(parents=True, exist_ok=True)
    return batch_dir


def main():
    args = parse_args()
    locations = maybe_filter_locations(load_locations(), args.locations)
    run_dir = ensure_tmp_dir()
    summary = []
    combined_slugs = []
    combined_seen = set()

    for entry in locations:
        loc_id = entry.get("id") or entry.get("name")
        loc_name = entry.get("name", loc_id)
        print("\n" + "=" * 80)
        print(f"ğŸŒ å¤„ç†åœ°ç‚¹: {loc_name} ({loc_id})")

        try:
            start_date, end_date = resolve_date_range(entry, args)
        except ValueError as exc:
            print(f"âŒ æ—¥æœŸé”™è¯¯: {exc}")
            summary.append(
                {"location": loc_name, "status": "æ—¥æœŸé”™è¯¯", "details": str(exc)}
            )
            continue

        location_dir = run_dir / loc_id
        location_dir.mkdir(parents=True, exist_ok=True)
        text_file = location_dir / "birds.txt"
        csv_file = location_dir / "birds.csv"

        try:
            records = fetch_species_for_location(entry, start_date, end_date, text_file)
        except Exception as exc:
            print(f"âŒ æŠ“å–å¤±è´¥: {exc}")
            summary.append(
                {"location": loc_name, "status": "æŠ“å–å¤±è´¥", "details": str(exc)}
            )
            continue

        species_count = len(records)
        print(f"ğŸ“Š {loc_name} å»é‡é¸Ÿç§: {species_count}")

        # å¦‚æœæ•°é‡å°‘äºé˜ˆå€¼ï¼Œç»™å‡ºè­¦å‘Šä½†ç»§ç»­å¤„ç†
        if species_count < max(1, args.min_species):
            print(
                f"âš ï¸  è­¦å‘Šï¼šå°‘äº {args.min_species} ç§ï¼ˆå½“å‰ {species_count} ç§ï¼‰ï¼Œä½†ä»ä¼šç»§ç»­å¤„ç†"
            )

        slug_info = write_csv_from_records(records, csv_file)

        merge_with_all_birds_csv(csv_file)
        missing_local = check_missing_birds(csv_file)
        downloads_for_log = sorted(set(missing_local))
        remaining_local = list(missing_local)
        for attempt in range(1, MAX_RETRIES + 1):
            if not remaining_local:
                break
            print(f"ğŸ” ä¸‹è½½ç¼ºå¤±é¸Ÿç±»ï¼Œç¬¬ {attempt}/{MAX_RETRIES} æ¬¡å°è¯•ï¼ˆ{len(remaining_local)} ç§ï¼‰")
            ok = download_birds(csv_file, remaining_local)
            if not ok:
                print("âš ï¸  ä¸‹è½½å‘½ä»¤å¤±è´¥ï¼Œåœæ­¢é‡è¯•")
                break
            # é‡æ–°æ£€æŸ¥ï¼šæ£€æŸ¥æœ¬åœ°å›¾ç‰‡æ–‡ä»¶
            # å¦‚æœæœ¬åœ°æœ‰å›¾ç‰‡ï¼Œè¯´æ˜ä¸‹è½½æˆåŠŸï¼›åç»­ä¼šä¸Šä¼ ï¼Œæ‰€ä»¥è¿™é‡Œåªæ£€æŸ¥æœ¬åœ°å›¾ç‰‡
            new_missing = []
            for slug in remaining_local:
                bird_path = PROJECT_ROOT / "images" / slug
                has_images = False
                if bird_path.exists():
                    for source_dir in ['macaulay', 'inaturalist', 'wikimedia', 'avibase']:
                        source_path = bird_path / source_dir
                        if source_path.exists():
                            image_files = list(source_path.glob("*.jpg")) + list(source_path.glob("*.jpeg")) + list(source_path.glob("*.png"))
                            if image_files:
                                has_images = True
                                break
                if not has_images:
                    new_missing.append(slug)
            remaining_local = new_missing
        if remaining_local:
            print(f"âš ï¸  ä»æœ‰ {len(remaining_local)} ç§é¸Ÿç±»æ²¡æœ‰æˆåŠŸä¸‹è½½æœ¬åœ°å›¾ç‰‡ï¼š{', '.join(remaining_local)}")

        missing_cloud = check_missing_cloudinary(csv_file)
        remaining_cloud = list(missing_cloud)
        for attempt in range(1, MAX_RETRIES + 1):
            if not remaining_cloud:
                break
            print(f"ğŸ” ä¸Šä¼ ç¼ºå¤±é¸Ÿç±»åˆ° Cloudinaryï¼Œç¬¬ {attempt}/{MAX_RETRIES} æ¬¡å°è¯•ï¼ˆ{len(remaining_cloud)} ç§ï¼‰")
            ok = upload_to_cloudinary(remaining_cloud, csv_file)
            if not ok:
                print("âš ï¸  ä¸Šä¼ å‘½ä»¤å¤±è´¥ï¼Œåœæ­¢é‡è¯•")
                break
            new_missing_cloud = check_missing_cloudinary(csv_file)
            remaining_cloud = [slug for slug in new_missing_cloud if slug in remaining_cloud]
        if remaining_cloud:
            print(f"âš ï¸  ä»æœ‰ {len(remaining_cloud)} ç§é¸Ÿç±»æœªä¸Šä¼ è‡³ Cloudinaryï¼š{', '.join(remaining_cloud)}")

        update_bird_info(csv_file)

        slugs = read_slugs_from_csv(csv_file)
        report_code = end_date.strftime("%y%m%d")
        
        # ä¸‹è½½å’Œä¸Šä¼ é¸Ÿå«å£°
        success_sounds, failed_sounds = download_and_upload_sounds(slugs, location_dir)
        
        # å¤åˆ¶ JSON åˆ° location_birdsï¼ˆåŒ…å«æ–°ä¸‹è½½çš„ soundsï¼‰
        dest_dir, copied, missing_copy = copy_json_to_location(
            slugs, loc_name, report_code
        )

        for slug in slugs:
            if slug not in combined_seen:
                combined_slugs.append(slug)
                combined_seen.add(slug)

        # åœ¨ä¸Šä¼ å®Œæˆåï¼Œé‡æ–°æ£€æŸ¥æœ¬åœ°å›¾ç‰‡å’Œ Cloudinary JSON çŠ¶æ€
        # é€»è¾‘ï¼š
        # 1. å¦‚æœ Cloudinary JSON å­˜åœ¨ä¸”æœ‰ç…§ç‰‡ â†’ ä¸Šä¼ æˆåŠŸï¼Œæœ¬åœ°å›¾ç‰‡è‚¯å®šå­˜åœ¨ â†’ ä¸åº”è¯¥æ˜¾ç¤ºåœ¨"ä»ç¼ºæœ¬åœ°å›¾ç‰‡"ä¸­
        # 2. å¦‚æœ Cloudinary JSON ä¸å­˜åœ¨ï¼Œä½†æœ¬åœ°æœ‰å›¾ç‰‡ â†’ ä¸‹è½½æˆåŠŸä½†ä¸Šä¼ å¤±è´¥ â†’ ä¸åº”è¯¥æ˜¾ç¤ºåœ¨"ä»ç¼ºæœ¬åœ°å›¾ç‰‡"ä¸­ï¼ˆå› ä¸ºæœ¬åœ°æœ‰å›¾ç‰‡ï¼‰
        # 3. å¦‚æœ Cloudinary JSON ä¸å­˜åœ¨ï¼Œä¸”æœ¬åœ°ä¹Ÿæ²¡æœ‰å›¾ç‰‡ â†’ ä¸‹è½½å¤±è´¥ â†’ åº”è¯¥æ˜¾ç¤ºåœ¨"ä»ç¼ºæœ¬åœ°å›¾ç‰‡"ä¸­
        final_missing_local = []
        for slug in remaining_local:
            # æ£€æŸ¥æœ¬åœ°å›¾ç‰‡
            bird_path = PROJECT_ROOT / "images" / slug
            has_images = False
            if bird_path.exists():
                for source_dir in ['macaulay', 'inaturalist', 'wikimedia', 'avibase']:
                    source_path = bird_path / source_dir
                    if source_path.exists():
                        image_files = list(source_path.glob("*.jpg")) + list(source_path.glob("*.jpeg")) + list(source_path.glob("*.png"))
                        if image_files:
                            has_images = True
                            break
            
            # åªæœ‰çœŸæ­£æ²¡æœ‰æœ¬åœ°å›¾ç‰‡çš„æ‰æ˜¾ç¤ºåœ¨"ä»ç¼ºæœ¬åœ°å›¾ç‰‡"ä¸­
            # å¦‚æœæœ¬åœ°æœ‰å›¾ç‰‡ä½† Cloudinary JSON ä¸å­˜åœ¨ï¼Œè¯´æ˜ä¸Šä¼ å¤±è´¥ï¼Œä¼šæ˜¾ç¤ºåœ¨"ç¼ºå°‘ cloudinary JSON"ä¸­
            if not has_images:
                final_missing_local.append(slug)
        
        # ç¡®å®šçŠ¶æ€ï¼šå¦‚æœæ•°é‡å°‘äºé˜ˆå€¼ï¼Œæ ‡è®°ä¸º"å·²æ›´æ–°ï¼ˆæ•°é‡è¾ƒå°‘ï¼‰"
        status = "å·²æ›´æ–°"
        if species_count < max(1, args.min_species):
            status = f"å·²æ›´æ–°ï¼ˆ{species_count}ç§ï¼Œå°‘äº{args.min_species}ç§é˜ˆå€¼ï¼‰"
        
        summary.append(
            {
                "location": loc_name,
                "status": status,
                "details": f"{species_count} ç§ -> å¤åˆ¶ {copied} JSON è‡³ {dest_dir}",
                "downloads": format_slug_list(downloads_for_log, slug_info),
                "downloads_raw": downloads_for_log,  # ä¿å­˜åŸå§‹ slug åˆ—è¡¨
                "missing_local": format_slug_list(final_missing_local, slug_info),
                "missing_json": format_slug_list(missing_copy, slug_info),
                "sounds_success": len(success_sounds),
                "sounds_failed": len(failed_sounds),
                "sounds_failed_details": failed_sounds,
            }
        )

    # æ”¶é›†æ‰€æœ‰æˆåŠŸå¤„ç†çš„åœ°ç‚¹ï¼ˆåŒ…æ‹¬æ•°é‡è¾ƒå°‘ä½†ä»å¤„ç†çš„åœ°ç‚¹ï¼‰
    successful = [item for item in summary if item["status"].startswith("å·²æ›´æ–°")]

    if successful:
        print("\nğŸ” å…¨å±€æ›´æ–° all_birds.csv / HTML ...")
        update_all_birds_csv()
        
        # æ”¶é›†æ‰€æœ‰éœ€è¦é«˜äº®çš„é¸Ÿç±»ï¼ˆå³æ‰€æœ‰ä¸‹è½½çš„é¸Ÿç±»ï¼‰
        highlight_slugs = []
        for item in summary:
            downloads_raw = item.get("downloads_raw") or []
            highlight_slugs.extend(downloads_raw)
        
        # å»é‡
        highlight_slugs = list(set(highlight_slugs))
        
        # æš‚æ—¶ç”ŸæˆHTMLï¼ˆæ­¤æ—¶è¿˜æ²¡æœ‰æ”¶é›†åˆ°æ‰€æœ‰éœ€è¦ä¸‹è½½/æ£€æŸ¥çš„é¸Ÿç±»ï¼‰
        generate_html(highlight_slugs, priority_slugs=highlight_slugs)

        if combined_slugs:
            combined_csv = run_dir / "combined_reorder.csv"
            with open(combined_csv, "w", encoding="utf-8", newline="") as f:
                writer = csv.writer(f)
                writer.writerow(["slug", "english_name", "scientific_name", "wikipedia_page"])
                for slug in combined_slugs:
                    writer.writerow([slug, "", "", ""])
            reorder_new_birds(combined_csv)

    # æ£€æŸ¥ all_birds.csv ä¸­æ‰€æœ‰ç¼ºå°‘ cloudinary JSON çš„é¸Ÿç±»
    # æ³¨æ„ï¼šåœ¨ update_all_birds_csv() ä¹‹åæ‰§è¡Œï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°çš„ all_birds.csv
    print("\n" + "=" * 80)
    print("ğŸ” æ£€æŸ¥ all_birds.csv ä¸­æ‰€æœ‰ç¼ºå°‘ cloudinary JSON çš„é¸Ÿç±»...")
    all_birds_map = load_all_birds_csv()
    print(f"ğŸ“‹ ä» all_birds.csv åŠ è½½äº† {len(all_birds_map)} ä¸ªé¸Ÿç±»")
    
    all_missing_birds = []
    birds_with_json_and_photos = []
    birds_with_json_but_no_photos = []
    birds_without_json = []
    remaining_all_missing = []  # åœ¨æ›´å¤–å±‚å®šä¹‰ï¼Œä»¥ä¾¿æœ€åç”ŸæˆHTMLæ—¶ä½¿ç”¨
    
    for slug, bird_info in all_birds_map.items():
        json_file = PROJECT_ROOT / "cloudinary_uploads" / f"{slug}_cloudinary_urls.json"
        has_cloudinary_data = False
        photo_count = 0
        json_exists = json_file.exists()
        
        if json_exists:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for source in ['macaulay', 'inaturalist', 'wikimedia', 'avibase']:
                        if source in data and isinstance(data[source], list):
                            photo_count += len(data[source])
                    has_cloudinary_data = photo_count > 0
            except Exception as e:
                has_cloudinary_data = False
                print(f"  âš ï¸  {slug}: JSON æ–‡ä»¶è¯»å–å¤±è´¥ - {e}")
        
        if has_cloudinary_data:
            birds_with_json_and_photos.append(slug)
        elif json_exists:
            birds_with_json_but_no_photos.append(slug)
            all_missing_birds.append(slug)
        else:
            birds_without_json.append(slug)
            all_missing_birds.append(slug)
    
    # è¯¦ç»†æ—¥å¿—è¾“å‡º
    print(f"\nğŸ“Š æ£€æŸ¥ç»“æœç»Ÿè®¡:")
    print(f"  âœ… æœ‰ JSON ä¸”æœ‰ç…§ç‰‡: {len(birds_with_json_and_photos)} ä¸ª")
    print(f"  âš ï¸  æœ‰ JSON ä½†æ— ç…§ç‰‡: {len(birds_with_json_but_no_photos)} ä¸ª")
    print(f"  âŒ æ²¡æœ‰ JSON æ–‡ä»¶: {len(birds_without_json)} ä¸ª")
    print(f"  ğŸ“‹ æ€»è®¡éœ€è¦å¤„ç†: {len(all_missing_birds)} ä¸ª")
    
    if birds_with_json_but_no_photos:
        print(f"\nâš ï¸  æœ‰ JSON ä½†æ— ç…§ç‰‡çš„é¸Ÿç±»ï¼ˆå‰10ä¸ªï¼‰:")
        for slug in birds_with_json_but_no_photos[:10]:
            bird_info = all_birds_map.get(slug, {})
            name = bird_info.get('chinese_name', '') or bird_info.get('english_name', slug)
            print(f"    - {slug} ({name})")
        if len(birds_with_json_but_no_photos) > 10:
            print(f"    ... è¿˜æœ‰ {len(birds_with_json_but_no_photos) - 10} ä¸ª")
    
    if birds_without_json:
        print(f"\nâŒ æ²¡æœ‰ JSON æ–‡ä»¶çš„é¸Ÿç±»ï¼ˆå‰10ä¸ªï¼‰:")
        for slug in birds_without_json[:10]:
            bird_info = all_birds_map.get(slug, {})
            name = bird_info.get('chinese_name', '') or bird_info.get('english_name', slug)
            print(f"    - {slug} ({name})")
        if len(birds_without_json) > 10:
            print(f"    ... è¿˜æœ‰ {len(birds_without_json) - 10} ä¸ª")
    
    if all_missing_birds:
        print(f"\nğŸ“‹ å‘ç° {len(all_missing_birds)} ä¸ªé¸Ÿç±»ç¼ºå°‘ cloudinary JSONï¼Œå°è¯•ä¸‹è½½...")
        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶ CSV æ–‡ä»¶åŒ…å«æ‰€æœ‰ç¼ºå¤±çš„é¸Ÿç±»
        temp_all_missing_csv = run_dir / "all_missing_birds.csv"
        with open(temp_all_missing_csv, 'w', encoding='utf-8') as f:
            f.write('# slug,chinese_name,english_name,scientific_name,wikipedia_page\n')
            for slug in all_missing_birds:
                bird_info = all_birds_map[slug]
                chinese = bird_info.get('chinese_name', '')
                english = bird_info.get('english_name', '')
                scientific = bird_info.get('scientific_name', '')
                wiki = bird_info.get('wikipedia_page', '')
                if not wiki and english:
                    wiki = english.replace(' ', '_')
                f.write(f'{slug},"{chinese}","{english}","{scientific}",{wiki}\n')
        
        # å°è¯•ä¸‹è½½è¿™äº›ç¼ºå¤±çš„é¸Ÿç±»
        remaining_all_missing = list(all_missing_birds)  # æ›´æ–°å¤–å±‚å˜é‡
        for attempt in range(1, MAX_RETRIES + 1):
            if not remaining_all_missing:
                break
            print(f"\nğŸ” ä¸‹è½½ all_birds.csv ä¸­ç¼ºå¤±çš„é¸Ÿç±»ï¼Œç¬¬ {attempt}/{MAX_RETRIES} æ¬¡å°è¯•ï¼ˆ{len(remaining_all_missing)} ç§ï¼‰")
            ok = download_birds(temp_all_missing_csv, remaining_all_missing)
            if not ok:
                print("âš ï¸  ä¸‹è½½å‘½ä»¤å¤±è´¥ï¼Œåœæ­¢é‡è¯•")
                break
            # é‡æ–°æ£€æŸ¥ç¼ºå¤±çš„é¸Ÿç±»
            new_all_missing = []
            for slug in remaining_all_missing:
                json_file = PROJECT_ROOT / "cloudinary_uploads" / f"{slug}_cloudinary_urls.json"
                has_data = False
                if json_file.exists():
                    try:
                        with open(json_file, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                            photo_count = 0
                            for source in ['macaulay', 'inaturalist', 'wikimedia', 'avibase']:
                                if source in data and isinstance(data[source], list):
                                    photo_count += len(data[source])
                            has_data = photo_count > 0
                    except Exception:
                        pass
                if not has_data:
                    new_all_missing.append(slug)
            remaining_all_missing = new_all_missing
        
        # æ£€æŸ¥å“ªäº›é¸Ÿç±»æˆåŠŸä¸‹è½½äº†å›¾ç‰‡ï¼ˆæœ¬åœ°æœ‰å›¾ç‰‡ï¼‰
        print(f"\nğŸ“ æ£€æŸ¥æœ¬åœ°å›¾ç‰‡æ–‡ä»¶...")
        birds_with_images = []
        birds_without_images = []
        for slug in all_missing_birds:
            bird_path = PROJECT_ROOT / "images" / slug
            if bird_path.exists():
                # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å›¾ç‰‡æ–‡ä»¶
                has_images = False
                total_images = 0
                for source_dir in ['macaulay', 'inaturalist', 'wikimedia', 'avibase']:
                    source_path = bird_path / source_dir
                    if source_path.exists():
                        image_files = list(source_path.glob("*.jpg")) + list(source_path.glob("*.jpeg")) + list(source_path.glob("*.png"))
                        total_images += len(image_files)
                        if image_files:
                            has_images = True
                if has_images:
                    birds_with_images.append(slug)
                    bird_info = all_birds_map.get(slug, {})
                    name = bird_info.get('chinese_name', '') or bird_info.get('english_name', slug)
                    print(f"  âœ… {slug} ({name}): æœ‰ {total_images} å¼ æœ¬åœ°å›¾ç‰‡")
                else:
                    birds_without_images.append(slug)
            else:
                birds_without_images.append(slug)
        
        print(f"\nğŸ“Š æœ¬åœ°å›¾ç‰‡æ£€æŸ¥ç»“æœ:")
        print(f"  âœ… æœ‰æœ¬åœ°å›¾ç‰‡: {len(birds_with_images)} ä¸ª")
        print(f"  âŒ æ— æœ¬åœ°å›¾ç‰‡: {len(birds_without_images)} ä¸ª")
        
        if remaining_all_missing:
            print(f"\nâš ï¸  ä»æœ‰ {len(remaining_all_missing)} ç§é¸Ÿç±»æœªæˆåŠŸä¸‹è½½ï¼ˆJSON æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— ç…§ç‰‡ï¼‰")
            if len(remaining_all_missing) <= 20:
                for slug in remaining_all_missing:
                    bird_info = all_birds_map.get(slug, {})
                    name = bird_info.get('chinese_name', '') or bird_info.get('english_name', slug)
                    print(f"    - {slug} ({name})")
            else:
                for slug in remaining_all_missing[:10]:
                    bird_info = all_birds_map.get(slug, {})
                    name = bird_info.get('chinese_name', '') or bird_info.get('english_name', slug)
                    print(f"    - {slug} ({name})")
                print(f"    ... è¿˜æœ‰ {len(remaining_all_missing) - 10} ä¸ª")
        else:
            print(f"\nâœ… æ‰€æœ‰ç¼ºå¤±çš„é¸Ÿç±»å·²æˆåŠŸä¸‹è½½")
        
        # åªä¸Šä¼ æœ‰æœ¬åœ°å›¾ç‰‡çš„é¸Ÿç±»åˆ° Cloudinary
        # æ£€æŸ¥å“ªäº›é¸Ÿç±»éœ€è¦ä¸Šä¼ ï¼ˆJSONæ–‡ä»¶ä¸å­˜åœ¨æˆ–æ²¡æœ‰æœ‰æ•ˆç…§ç‰‡æ•°æ®ï¼‰
        print(f"\nâ˜ï¸  æ£€æŸ¥éœ€è¦ä¸Šä¼ åˆ° Cloudinary çš„é¸Ÿç±»...")
        all_missing_cloud = []
        birds_already_uploaded = []
        for slug in birds_with_images:
            json_file = PROJECT_ROOT / "cloudinary_uploads" / f"{slug}_cloudinary_urls.json"
            has_cloudinary_data = False
            photo_count = 0
            if json_file.exists():
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        for source in ['macaulay', 'inaturalist', 'wikimedia', 'avibase']:
                            if source in data and isinstance(data[source], list):
                                photo_count += len(data[source])
                        has_cloudinary_data = photo_count > 0
                except Exception:
                    pass
            
            if has_cloudinary_data:
                birds_already_uploaded.append(slug)
                bird_info = all_birds_map.get(slug, {})
                name = bird_info.get('chinese_name', '') or bird_info.get('english_name', slug)
                print(f"  âœ… {slug} ({name}): å·²ä¸Šä¼ ï¼ˆ{photo_count} å¼ ç…§ç‰‡ï¼‰")
            else:
                all_missing_cloud.append(slug)
                bird_info = all_birds_map.get(slug, {})
                name = bird_info.get('chinese_name', '') or bird_info.get('english_name', slug)
                print(f"  âŒ {slug} ({name}): éœ€è¦ä¸Šä¼ ï¼ˆJSONæ–‡ä»¶{'å­˜åœ¨ä½†æ— ç…§ç‰‡' if json_file.exists() else 'ä¸å­˜åœ¨'}ï¼‰")
        
        print(f"\nğŸ“Š ä¸Šä¼ æ£€æŸ¥ç»“æœ:")
        print(f"  âœ… å·²ä¸Šä¼ : {len(birds_already_uploaded)} ä¸ª")
        print(f"  âŒ éœ€è¦ä¸Šä¼ : {len(all_missing_cloud)} ä¸ª")
        
        if all_missing_cloud:
            print(f"\nğŸ” ä¸Šä¼  {len(all_missing_cloud)} ä¸ªæœ‰æœ¬åœ°å›¾ç‰‡ä½†ç¼ºå°‘ cloudinary JSON çš„é¸Ÿç±»åˆ° Cloudinary...")
            upload_to_cloudinary(all_missing_cloud, temp_all_missing_csv)
        else:
            if birds_with_images:
                print(f"\nâœ… æ‰€æœ‰æœ‰æœ¬åœ°å›¾ç‰‡çš„é¸Ÿç±»éƒ½å·²ä¸Šä¼ åˆ° Cloudinary")
            else:
                print(f"\nâš ï¸  æ²¡æœ‰é¸Ÿç±»æˆåŠŸä¸‹è½½å›¾ç‰‡ï¼Œè·³è¿‡ä¸Šä¼ æ­¥éª¤")
    else:
        print("\nâœ… all_birds.csv ä¸­æ‰€æœ‰é¸Ÿç±»éƒ½æœ‰ cloudinary JSON")

    print("\n" + "=" * 80)
    print("ğŸ“‹ ä»»åŠ¡æ‘˜è¦")
    
    # æ±‡æ€»æ‰€æœ‰éœ€è¦ä¸‹è½½å’Œç¼ºæœ¬åœ°å›¾ç‰‡çš„é¸Ÿç±»
    all_downloads = set()
    all_missing_local = set()
    all_missing_json = set()
    
    for item in summary:
        print(f"- {item['location']}: {item['status']} ({item.get('details','')})")
        downloads = item.get("downloads") or []
        missing_local = item.get("missing_local") or []
        missing_json = item.get("missing_json") or []
        
        all_downloads.update(downloads)
        all_missing_local.update(missing_local)
        all_missing_json.update(missing_json)
    
    # æ±‡æ€»è¾“å‡º
    if all_downloads or all_missing_local or all_missing_json:
        downloaded_count = len(all_downloads) - len(all_missing_local)
        uploaded_count = len(all_downloads) - len(all_missing_json)
        
        print(f"\nğŸ“Š æ±‡æ€»ç»Ÿè®¡:")
        print(f"  Â· ç¼ºå¤±çš„æ–°é¸Ÿç±»: {len(all_downloads)} ç§")
        print(f"  Â· å·²æˆåŠŸä¸‹è½½çš„é¸Ÿç±»: {downloaded_count} ç§")
        print(f"  Â· å·²æˆåŠŸä¸Šä¼ çš„é¸Ÿç±»: {uploaded_count} ç§ï¼ˆéœ€æ£€æŸ¥å›¾ç‰‡ï¼‰")
        print(f"  Â· ä»ç¼ºæœ¬åœ°å›¾ç‰‡çš„é¸Ÿç±»: {len(all_missing_local)} ç§")
        print(f"  Â· ç¼ºå°‘ cloudinary JSON çš„é¸Ÿç±»: {len(all_missing_json)} ç§")
        
        # ç»Ÿè®¡å£°éŸ³ä¸‹è½½æƒ…å†µ
        total_sounds_success = sum(item.get("sounds_success", 0) for item in successful)
        total_sounds_failed = sum(item.get("sounds_failed", 0) for item in successful)
        if total_sounds_success > 0 or total_sounds_failed > 0:
            print(f"  Â· é¸Ÿå«å£°ä¸‹è½½æˆåŠŸ: {total_sounds_success} ç§")
            if total_sounds_failed > 0:
                print(f"  Â· é¸Ÿå«å£°ä¸‹è½½å¤±è´¥: {total_sounds_failed} ç§")
        
        if all_downloads:
            print(f"\nğŸ“¥ éœ€è¦ä¸‹è½½/æ£€æŸ¥çš„é¸Ÿç±»ï¼ˆ{len(all_downloads)} ç§ï¼‰:")
            for bird in sorted(all_downloads):
                print(f"    - {bird}")
        
        if all_missing_local:
            print(f"\nâŒ ä»ç¼ºæœ¬åœ°å›¾ç‰‡çš„é¸Ÿç±»ï¼ˆ{len(all_missing_local)} ç§ï¼‰:")
            for bird in sorted(all_missing_local):
                print(f"    - {bird}")
        
        if all_missing_json:
            print(f"\nâ˜ï¸  ç¼ºå°‘ cloudinary JSON çš„é¸Ÿç±»ï¼ˆ{len(all_missing_json)} ç§ï¼‰:")
            for bird in sorted(all_missing_json):
                print(f"    - {bird}")
        
        # æ˜¾ç¤ºå£°éŸ³ä¸‹è½½å¤±è´¥çš„è¯¦ç»†ä¿¡æ¯
        all_sounds_failed = []
        for item in successful:
            failed_details = item.get("sounds_failed_details", [])
            all_sounds_failed.extend(failed_details)
        
        if all_sounds_failed:
            print(f"\nğŸ”Š é¸Ÿå«å£°ä¸‹è½½å¤±è´¥çš„é¸Ÿç±»ï¼ˆ{len(all_sounds_failed)} ç§ï¼‰:")
            for bird in all_sounds_failed[:20]:  # æœ€å¤šæ˜¾ç¤º20ä¸ª
                name = bird.get('chinese_name') or bird['slug']
                reason = bird.get('reason', 'æœªçŸ¥åŸå› ')
                print(f"    - {name} ({bird['slug']}): {reason}")
            if len(all_sounds_failed) > 20:
                print(f"    ... è¿˜æœ‰ {len(all_sounds_failed) - 20} ä¸ª")

    print("\nâ„¹ï¸ è¯´æ˜ï¼šåˆ—è¡¨ä¸­çš„'ç¼ºå°‘ cloudinary JSON'ä»£è¡¨å¯¹åº”é¸Ÿç±»çš„å›¾ç‰‡å°šæœªæˆåŠŸä¸‹è½½æˆ–ä¸Šä¼ ã€‚å¯é‡è·‘ `run_weekly_refresh.py --locations <åœ°ç‚¹>`ï¼Œæˆ–æ‰‹åŠ¨ä½¿ç”¨ `tools/batch_fetch.sh` ä¸ `tools/upload_to_cloudinary.py` æ¥è¡¥é½ã€‚")

    print("\nğŸ§¾ æ‰‹åŠ¨æ­¥éª¤æé†’ï¼š")
    print("1. æ‰“å¼€ images/ æˆ– Cloudinary åå°æ£€æŸ¥æœ¬æ¬¡æ–°ä¸‹è½½çš„é¸Ÿç±»ï¼Œåˆ é™¤ä¸åˆé€‚çš„ç…§ç‰‡ã€‚")
    print("2. æ£€æŸ¥ Cloudinary ä¸­æ–°ä¸Šä¼ çš„é¸Ÿå«å£°ï¼Œç¡®è®¤éŸ³é¢‘è´¨é‡ã€‚")
    print("3. è¿è¡Œ `python3 tools/delete_cloudinary_by_list.py` ç­‰æ¸…ç†è„šæœ¬ï¼ˆå¦‚éœ€è¦ï¼‰ã€‚")
    print("4. ç™»å½• Lovableï¼Œè§¦å‘ç«™ç‚¹é‡æ–°éƒ¨ç½²/æ¨é€æ›´æ–°ã€‚")
    print("5. é€šè¿‡ `feather-flash-quiz/location_birds/<åœ°ç‚¹>/<æ—¥æœŸ>` æŸ¥çœ‹å¤åˆ¶ç»“æœã€‚")
    print("\nğŸ’¡ é¸Ÿå«å£°ä¸‹è½½å¤±è´¥çš„åŸå› é€šå¸¸æ˜¯ï¼š")
    print("   Â· eBirdæ•°æ®åº“ä¸­æ— æ­¤ç‰©ç§è®°å½•")
    print("   Â· Macaulay Libraryä¸­æ‰¾ä¸åˆ°è¯¥ç‰©ç§çš„éŸ³é¢‘")
    print("   Â· ç½‘ç»œé—®é¢˜å¯¼è‡´ä¸‹è½½å¤±è´¥")
    print("   å¯ä»¥æ‰‹åŠ¨ä½¿ç”¨ `python3 tools/batch_download_sounds.py` é‡è¯•")

    # æ”¶é›†æ‰€æœ‰éœ€è¦ä¸‹è½½/æ£€æŸ¥çš„é¸Ÿç±»ï¼ˆslugæ ¼å¼ï¼‰
    all_priority_slugs = set()
    all_highlight_slugs = set()
    
    # ä» summary ä¸­æ”¶é›† downloads_raw
    for item in summary:
        downloads_raw = item.get("downloads_raw") or []
        all_priority_slugs.update(downloads_raw)
        all_highlight_slugs.update(downloads_raw)
    
    # æ”¶é›† remaining_all_missingï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if remaining_all_missing:
        all_priority_slugs.update(remaining_all_missing)
        all_highlight_slugs.update(remaining_all_missing)
    
    # å¦‚æœæœ‰éœ€è¦ä¸‹è½½/æ£€æŸ¥çš„é¸Ÿç±»ï¼Œé‡æ–°ç”ŸæˆHTMLï¼Œè®©å®ƒä»¬æ’åœ¨æœ€å‰é¢å¹¶æ ‡çº¢
    if all_priority_slugs:
        print(f"\nğŸ”„ é‡æ–°ç”ŸæˆHTMLï¼Œå°† {len(all_priority_slugs)} ä¸ªéœ€è¦ä¸‹è½½/æ£€æŸ¥çš„é¸Ÿç±»æ’åœ¨æœ€å‰é¢å¹¶æ ‡çº¢...")
        generate_html(highlight_slugs=list(all_highlight_slugs), priority_slugs=list(all_priority_slugs))
    
    # è‡ªåŠ¨æ‰“å¼€ HTML é¡µé¢
    if successful and all_downloads:
        html_file = PROJECT_ROOT / "examples" / "gallery_all_cloudinary.html"
        if html_file.exists():
            print(f"\nğŸŒ æ­£åœ¨æ‰“å¼€ HTML é¡µé¢: {html_file}")
            try:
                subprocess.run(["open", str(html_file)], check=False)
            except Exception as e:
                print(f"âš ï¸  è‡ªåŠ¨æ‰“å¼€å¤±è´¥: {e}ï¼Œè¯·æ‰‹åŠ¨æ‰“å¼€ {html_file}")

    return 0 if successful else 1


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\nç”¨æˆ·å–æ¶ˆã€‚")
        sys.exit(1)
